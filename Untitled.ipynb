{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0081623-ddf7-4eea-9904-1237d1385270",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5515a157-74b4-423c-9910-643c6ef5898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import jit, vmap\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5c520e-e429-453d-b493-0e01d7c4bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"0.95\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b108b2a0-1b13-4611-ae2e-19ad8c80f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c277e07d-1e90-4118-bc91-1dca1cf02b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cuda(id=0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ab576d-3fc4-4f49-a779-8cb123209ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 17:49:47.102242: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.5.40). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9197164e-9ae0-4615-8582-9b93f5c06ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0d50ae-425f-4f88-b4f9-0520b6ef759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae_jax import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb27bf5-75c3-4fe7-a89f-8943e2cc6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, vae_states = eqx.nn.make_with_state(VAE)(256, key)\n",
    "init_vae_params, vae_static = eqx.partition(vae, eqx.is_inexact_array)\n",
    "# x = jnp.zeros((1, 3, 256, 256)) # we must have a batch_dim, the model can only be applied afetr vmap because of BN layer\n",
    "# batch_model = jax.vmap(model, in_axes=(0, None, None, None), out_axes=(0, None), axis_name=\"batch\")\n",
    "# x, state = batch_model(x, state, key, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b136a3-1b10-4b5f-a358-87477ffcf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_train_dataloader, get_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77be5b34-6d1e-4bde-9da5-1a236a79e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2be38c-7611-4f9b-a4b7-d6f311bf79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import LivestockTrainDataset\n",
    "train_dataset = LivestockTrainDataset(\n",
    "    img_size,\n",
    "    fake_dataset_size=50000,\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aafa604-c820-494f-8233-ff958c0b6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(1, 5, 6))\n",
    "def loss(params, static, states, x, key, train=True, beta=1.):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    params\n",
    "        XXX\n",
    "    static\n",
    "        XXX\n",
    "    states\n",
    "        XXX\n",
    "    x\n",
    "        A batch of inputs\n",
    "    key\n",
    "        A JAX PRNGKey\n",
    "    \"\"\"\n",
    "    vae = eqx.combine(params, static)\n",
    "    if train:\n",
    "        # make sure we are in training mode\n",
    "        vae = eqx.nn.inference_mode(vae, value=False)\n",
    "    else:\n",
    "        vae = eqx.nn.inference_mode(vae)\n",
    "    batched_vae = vmap(vae, in_axes=(0, None, None, None), out_axes=(0, None, 0, 0), axis_name=\"batch\")\n",
    "\n",
    "    key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "    x_rec, state, mu, logvar = batched_vae(x, states, key, train)\n",
    "    print(x_rec)\n",
    "    batched_elbo = vmap(vae.elbo, in_axes=(0, 0, 0, 0, None), out_axes=(0, 0, 0))\n",
    "\n",
    "    elbo, rec_term, kld = batched_elbo(x_rec, x, mu, logvar, beta)\n",
    "    elbo = jnp.mean(elbo) # avg over the batches\n",
    "    rec_term = jnp.mean(rec_term)\n",
    "    kld = jnp.mean(kld)\n",
    "\n",
    "    x_rec = VAE.mean_from_lambda(jnp.mean(x_rec, axis=1))\n",
    "\n",
    "    return -elbo, (x_rec, rec_term, kld, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fbc4f-f9d6-44f7-a5ce-d485dd10fa21",
   "metadata": {},
   "source": [
    "Test the loss on one mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958301ff-6d72-41e2-a7cc-3403972b11a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 32, 32)\n",
      "Traced<ShapedArray(float32[16,50,3,256,256])>with<DynamicJaxprTrace(level=1/0)>\n"
     ]
    }
   ],
   "source": [
    "mini_batch = next(iter(train_dataloader))\n",
    "loss_value, (_, _, _, vae_states) = loss(init_vae_params, vae_static, vae_states, mini_batch[0].numpy(), key, train=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6587ff-424f-4877-8405-318f67c1212d",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bfb534d-0408-4a26-8178-5754202e4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "init_params = init_vae_params\n",
    "init_states = vae_states\n",
    "static = vae_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6cdcf9e-c250-4d95-8e81-ce1316cdb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = eqx.combine(init_params, static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1394fd-26b4-480b-86b5-3d47e08001d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "n_steps = 50\n",
    "learning_rate = 1e-3\n",
    "print_every = 1\n",
    "beta = 1\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "opt_state = optimizer.init(init_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548bb682-1bad-4235-a474-6302c0f67cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_steps, params, static, states, train_loader, opt_state, key, print_every):\n",
    "\n",
    "    def infinite_train_loader():\n",
    "        while True:\n",
    "            yield from train_loader\n",
    "\n",
    "    def make_step(x, params, states, opt_state, key):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        (minus_elbo, aux_loss), grads = jax.value_and_grad(loss, has_aux=True)(params, static, states, x, subkey, train=True, beta=beta)\n",
    "        x_rec, rec_term, kld, states = aux_loss\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, states, opt_state, key, x_rec, (minus_elbo, rec_term, kld)\n",
    "\n",
    "    elbo_list = []\n",
    "    rec_term_list = []\n",
    "    kld_list = []\n",
    "\n",
    "\n",
    "    for step, (x, _) in zip(range(n_steps), infinite_train_loader()): \n",
    "        x = x.numpy()\n",
    "\n",
    "        params, states, opt_state, key, x_rec, losses = make_step(x, params, states, opt_state, key)\n",
    "        elbo_list.append(-losses[0])\n",
    "        rec_term_list.append(losses[1])\n",
    "        kld_list.append(losses[2])\n",
    "        \n",
    "        if (step % print_every) == 0 or (step == n_steps - 1):\n",
    "            print(\n",
    "                f\"{step=}, elbo_loss={elbo_list[-1]}, rec_term={rec_term_list[-1]}, kld_term={kld_list[-1]}\"\n",
    "            )\n",
    "        \n",
    "            \n",
    "    return params, states, (elbo_list, rec_term_list, kld_list), opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "540a810f-bd72-4da6-b317-5f9c555c9d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 32, 32)\n",
      "Traced<ShapedArray(float32[16,50,3,256,256])>with<DynamicJaxprTrace(level=3/0)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 17:50:01.909979: W external/xla/xla/service/hlo_rematerialization.cc:2948] Can't reduce memory use below -18.49GiB (-19854978070 bytes) by rematerialization; only reduced to 24.63GiB (26451676305 bytes), down from 24.63GiB (26451676305 bytes) originally\n",
      "2024-06-03 17:50:13.054486: W external/tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.56GiB (rounded to 1677721600)requested by op \n",
      "2024-06-03 17:50:13.055550: W external/tsl/tsl/framework/bfc_allocator.cc:494] *******************************************************************************************_________\n",
      "E0603 17:50:13.056539  155235 pjrt_stream_executor_client.cc:2826] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1677721600 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:   15.65MiB\n",
      "              constant allocation:         6B\n",
      "        maybe_live_out allocation:   23.07GiB\n",
      "     preallocated temp allocation:    18.8KiB\n",
      "                 total allocation:   23.09GiB\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 1.56GiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,32,128,128]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 1.56GiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,32,128,128]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 1.56GiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,32,128,128]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 1.56GiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,32,128,128]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 1.56GiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,32,128,128]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,64,64,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,256,32,32]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,64,64,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,64,64,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,64,64,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 800.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,64,64,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 600.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,3,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 600.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,3,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 600.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,3,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 600.00MiB\n",
      "\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[50,16,3,256,256]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1677721600 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   15.65MiB\n              constant allocation:         6B\n        maybe_live_out allocation:   23.07GiB\n     preallocated temp allocation:    18.8KiB\n                 total allocation:   23.09GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.56GiB\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 800.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,256,32,32]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[0;32m----> 2\u001b[0m final_params, final_states, loss_lists, opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_every\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n_steps, params, static, states, train_loader, opt_state, key, print_every)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(n_steps), infinite_train_loader()): \n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 23\u001b[0m     params, states, opt_state, key, x_rec, losses \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     elbo_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m-\u001b[39mlosses[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     25\u001b[0m     rec_term_list\u001b[38;5;241m.\u001b[39mappend(losses[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mtrain.<locals>.make_step\u001b[0;34m(x, params, states, opt_state, key)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_step\u001b[39m(x, params, states, opt_state, key):\n\u001b[1;32m      8\u001b[0m     key, subkey \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(key)\n\u001b[0;32m----> 9\u001b[0m     (minus_elbo, aux_loss), grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     x_rec, rec_term, kld, states \u001b[38;5;241m=\u001b[39m aux_loss\n\u001b[1;32m     11\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state, params)\n",
      "    \u001b[0;31m[... skipping hidden 26 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/vae_grf/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1185\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1183\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1187\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1677721600 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   15.65MiB\n              constant allocation:         6B\n        maybe_live_out allocation:   23.07GiB\n     preallocated temp allocation:    18.8KiB\n                 total allocation:   23.09GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.56GiB\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 1.56GiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.4\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,32,128,128]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 800.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,256,32,32]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 800.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116 deduplicated_name=\"loop_dynamic_update_slice_fusion.12\"\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,64,64,64]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=167\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 600.00MiB\n\t\tOperator: op_name=\"jit(loss)/jit(main)/vmap(while)/body/dynamic_update_slice\" source_file=\"/home/hugo/Documents/writings/vae_grf_isprs/vae_grf/vae_jax.py\" source_line=116\n\t\tXLA Label: fusion\n\t\tShape: f32[50,16,3,256,256]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "final_params, final_states, loss_lists, opt_state = train(\n",
    "    n_steps, init_params, static, init_states, train_dataloader, opt_state, key, print_every=print_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd0210-005d-4184-8453-833a5c9cc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_lists[0], label=\"elbo\")\n",
    "plt.plot(loss_lists[1], label=\"rec_term\")\n",
    "plt.plot(loss_lists[2], label=\"kld\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1caf0b9-fb30-4f98-81d4-8cee30886fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import LivestockTestDataset\n",
    "test_dataset = LivestockTestDataset(\n",
    "    img_size,\n",
    "    fake_dataset_size=1024,\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e1487-a2e5-457e-bed4-8884e30abb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = next(iter(train_dataloader))\n",
    "x_test =  x_test[0].numpy()\n",
    "key, subkey = jax.random.split(key)\n",
    "(_, aux_loss) = loss(final_params, static, final_states, x_test, subkey, train=False, beta=beta)\n",
    "x_rec_test = aux_loss[0]\n",
    "print(jnp.mean(x_rec_test[0,0,10:-10,10:-10]), jnp.mean(x_test[0,0,10:-10,10:-10]))\n",
    "print(jnp.mean((x_rec_test[0,0,10:-10,10:-10]-x_test[0,0,10:-10,10:-10])**2))\n",
    "print(x_rec_test[0, 0,10:-10,10:-10], x_test[0,0,10:-10,10:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bea16-caf1-41b4-9a63-6e857909165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(2, 4)\n",
    "axes[0, 0].imshow(jnp.moveaxis(x_test[0],0, 2))\n",
    "axes[1, 0].imshow(jnp.moveaxis(x_rec_test[0], 0, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad7db2-3f25-45f9-ac37-06c8de9a3c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81170ade-1673-4aeb-ac9e-c39c622a3db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
